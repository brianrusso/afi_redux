Administrative Changes to AFI16-1003, Air Force Standard Analysis Toolkit  OPR:  HQ USAF/A9IB   Title page is hereby updated to include “Incorporating Updates Through 1 March 2011”. Title page is hereby updated to include current (as of 1 March 2011) OPR and Certification Official. Title page Releasability is hereby changed from “Distribution F” to “There are no releasability restrictions on this publication.” Opening paragraph is hereby updated to reflect approved wording from AFMAN 33-363, Management of Records, 1 March 2008. Opening paragraph is hereby updated to reflect current OPR information. Section A and all references to it are hereby changed to Chapter 1. Paragraph 1. and all references to it are hereby renumbered Paragraph 1.1. Paragraph 1.1. is hereby deleted. Paragraph 1.2. and all references to it are hereby renumbered Paragraph 1.1.1. Paragraph 1.3. and all references to it are hereby renumbered Paragraph 1.1.2. Paragraph 2. and all references to it are hereby renumbered Paragraph 1.2. Paragraph 3. and all references to it are hereby renumbered Paragraph 1.3. Paragraph 4. is hereby updated to include recognized acronyms AFAMS and AFMSRR. Paragraph 4. reference to the USAF/A9 website is updated to refer to the Air Force Portal. Paragraph 4. and all references to it are hereby renumbered Paragraph 1.4. Paragraph 5. and all references to it are hereby renumbered Paragraph 1.5. Paragraph 6. and all references to it are hereby renumbered Paragraph 1.6. Paragraph 6.1. reference to the USAF/A9 website is updated to refer to the Air Force Portal. Paragraph 6.1. and all references to it are hereby renumbered Paragraph 1.6.1. Paragraph 6.2. and all references to it are hereby renumbered Paragraph 1.6.2. Paragraph 6.3. and all references to it are hereby renumbered Paragraph 1.6.3. Section B and all references to it are hereby changed to Chapter 2. Paragraph 7. and all references to it are hereby renumbered Paragraph 2.1. Paragraph 8. and all references to it are hereby renumbered Paragraph 2.2. Paragraph 8.1. and all references to it are hereby renumbered Paragraph 2.2.1. Paragraph 8.2. and all references to it are hereby renumbered Paragraph 2.2.2. Paragraph 8.3. and all references to it are hereby renumbered Paragraph 2.2.3. Paragraph 8.4. and all references to it are hereby renumbered Paragraph 2.2.4. Paragraph 8.5. and all references to it are hereby renumbered Paragraph 2.2.5. Paragraph 8.6. and all references to it are hereby renumbered Paragraph 2.2.6. Paragraph 8.7. and all references to it are hereby renumbered Paragraph 2.2.7. Paragraph 9. and all references to it are hereby renumbered Paragraph 2.3. Paragraph 9.1. and all references to it are hereby renumbered Paragraph 2.3.1. Paragraph 9.2. and all references to it are hereby renumbered Paragraph 2.3.2. Paragraph 9.3. and all references to it are hereby renumbered Paragraph 2.3.3. Paragraph 9.4. and all references to it are hereby renumbered Paragraph 2.3.4. Paragraph 9.5. and all references to it are hereby renumbered Paragraph 2.3.5. Paragraph 9.6. and all references to it are hereby renumbered Paragraph 2.3.6. Paragraph 9.7. and all references to it are hereby renumbered Paragraph 2.3.7. Paragraph 10. and all references to it are hereby changed to Paragraph 2.4. Paragraph 10.1. and all references to it are hereby renumbered Paragraph 2.4.1. Paragraph 10.2. and all references to it are hereby renumbered Paragraph 2.4.2. Paragraph 10.3. and all references to it are hereby renumbered Paragraph 2.4.3. Paragraph 11. and all references to it are hereby renumbered Paragraph 2.5. Paragraph 11.1. and all references to it are hereby renumbered Paragraph 2.5.1. Paragraph 11.2 and all references to it are hereby renumbered Paragraph 2.5.2. Paragraph 11.3. and all references to it are hereby renumbered Paragraph 2.5.3. Paragraph 11.4. and all references to it are hereby renumbered Paragraph 2.5.4. Section C and all references to it are hereby changed to Chapter 3. Paragraph 12. and all references to it are hereby renumbered Paragraph 3.1. Paragraph 13. and all references to it are hereby renumbered Paragraph 3.2. Paragraph 14. and all references to it are hereby renumbered Paragraph 3.3. Paragraph 14.1. and all references to it are hereby renumbered Paragraph 3.3.1. Paragraph 14.2. and all references to it are hereby renumbered Paragraph 3.3.2. Paragraph 15. and all references to it are hereby renumbered Paragraph 3.4. Paragraph 16. and all references to it are hereby renumbered Paragraph 3.5. Attachment 1 reference DODD 5000.59, DoD Modeling and Simulation (M&S) Management, 4 January 1994 is hereby updated to the 8 August 2007 version of DODD 5000.59. Attachment 1 reference DODI 5000.61, DoD Modeling and Simulation (M&S) Verification, Validation, and Accreditation (VV&A), 13 May 2003 is hereby updated to the 9 December 2009 version of DODI 5000.61. Attachment 1 reference AFPD 16-10, Modeling and Simulation (M&S) Management is hereby updated to the 10 March 2006 version of AFPD 16-10. Attachment 1 reference AFI 16-1001, Verification, Validation and Accreditation (VV&A) is hereby updated to the 1 June 1996 version of 16-1001. Attachment 1 reference AFI 16-1002, Modeling and Simulation (M&S) Support to Acquisition is hereby updated to the 1 June 2000 version of 16-1002. Attachment 1 reference AFI 33-202, Volume I, Network and Computer Security is hereby updated to the newer AFI 33-200, Information Assurance Management, 23 December 2008. Attachment 1 reference AFMAN 37-123, (will convert to 33-363), Management of Records is hereby updated to AFMAN 33-363, Management of Records, 1 March 2008. Attachment  1  is  hereby  updated  to  include  AFAMS—Air  Force  Agency  for  Modeling and Simulation. Attachment 1 is hereby updated to remove AFB—Air Force Base. Attachment 1 is hereby updated to remove AFCA—Air Force Communications Agency. Attachment 1 is hereby updated to include AFMSRR—Air Force Modeling and Simulation Resource Repository. Attachment 1 is hereby updated to include DoD—Department of Defense. Attachment 1 is hereby updated to include DOD—Department of Defense Manual. Attachment 1 is hereby updated to remove IL—Illinois. Attachment 1 is hereby updated to remove IMT—Information Management Tool. Attachment 1 is hereby updated to remove NEWC—New and Emerging Warfighter Capabilities.  Attachment 1 is hereby updated to remove Accelerated Acquisition M&S Thrust. Attachment 1 is hereby updated to include Configuration Control Board. Attachment 1 is hereby updated to remove M&S Thrust. Attachment 1 is hereby updated to remove M&S Foundations Thrust. Attachment 1 is hereby updated to remove New and Emerging Warfighter Capabilities M&S Thrust. Attachment 1 is hereby updated to remove New and Emerging Warfighter Capabilities M&S Thrust Integrated Process Team. Attachment 1 is hereby updated to remove Warfighter Readiness M&S Thrust.  19 APRIL 2011 BY ORDER OF THESECRETARY OF THE AIR FORCE AIR FORCE INSTRUCTION 16-100317 FEBRUARY 2006Operations SupportAIR FORCE STANDARD ANALYSISTOOLKIT (AFSAT)COMPLIANCE WITH THIS PUBLICATION IS MANDATORYNOTICE:This publication is available digitally on the AFDPO WWW site at: http://www.e-publishing.af.mil.OPR: HQ USAF/A9IT  (Ms. Sharon Nichols) Certified by: HQ USAF/A9I  (Mr. Royce Reiss)Pages: 14Distribution: FThis instruction implements AFPD 16-10, Modeling and Simulation (M&S) Management. It describes theconcept and philosophy that underpin the AFSAT. It prescribes and explains the procedures and criteriafor entering new models into the AFSAT and for retiring models from the AFSAT. It assigns responsibil-ities for AFSAT management and covers the policies and procedures that govern the management of theAFSAT. It applies to all Air Force organizations and personnel managing or using tools in the AFSAT orproposing new tools for entry into the AFSAT. This Instruction does not apply to the Air Force ReserveCommand, but does apply to the Air National Guard. Ensure that all records created as a result of pro-cesses prescribed in this publication are maintained in accordance with AFMAN 37-123, (will convert to33-363) Management of Records and disposed of in accordance with the Air Force Records DispositionSchedule (RDS) located at https://afrims.amc.af.mil. Refer changes and conflicts between this and otherpublications to the OPR at HQ USAF/A9IT, 1570 Air Force Pentagon, Washington, DC 20330-1570, onAir Force (AF) Information Management Tool (IMT) 847, Recommendation for Change of Publica-tion. Send an information copy to HQ AFCA/EASD, 203 West Losey Street, Room 1100, Scott AFB, IL62225-5233. Major commands, field operating agencies, and direct reporting units may supplement thisinstruction. They must send one copy of their published or posted supplement to the OPR at HQ USAF/A9IT and a courtesy copy to HQ AFCA/EASD. See Attachment 1 for a glossary of references, abbreviations, acronyms and terms. Section A—AFSAT Background, Concept and Responsibilities 1.  Background and Concept. Digital models and simulations are among the most valuable tools com-monly used by the Air Force Analytic Community (AFAC). These tools are playing an increasinglyimportant role in supporting analyses that underpin key programmatic and acquisition decisions andassess alternative warfighting concepts, doctrine, strategies, tactics, and courses of action. The AFSAT isa collection of analytic computer models accepted and recommended by the AFAC for analysis in supportof decisions regarding strategic planning, capability requirements, and weapon systems development,acquisition, and testing. 2AFI16-1003   17 FEBRUARY 20061.1.  Air Force M&S efforts are organized around four Thrusts or emphasis areas: Warfighter Readi-ness, Accelerated Acquisition, New and Emerging Warfighter Capabilities (NEWC), and M&S Foun-dations. The AFSAT supports all four Thrust areas, but is most closely related to the NEWC Thrust,which focuses on M&S employed by the Air Force analytic, wargaming, and experimentation com-munities. The AFSAT Manager (see paragraph 4.) is also the co-chair of the NEWC Thrust IntegratedProcess Team (IPT). AFSAT models, among others, are also often employed to support the Acceler-ated Acquisition Thrust by providing tools that aid in requirements definition, capabilities assessment,concept exploration, and system design and evaluation. 1.2.  AFSAT models currently span the engagement, mission and campaign levels of modeling, sup-porting Air Force strategic, operational and tactical level analysis requirements. The AFSAT is a com-mon leveraging element in the employment of standard analysis practices and accepted tools thatprovide analytical insights for Air Force decision-makers. It is also a deliberate approach to publicizeaccepted models that address the goals of reducing proliferation of models, duplication of effort, andassociated model ownership costs. 1.3.  The AFSAT is centrally managed by HQ USAF/A9 under the auspices of the AFAC SteeringGroup (SG) with individual models managed by appropriate domain experts and model users. AFSATmodels meet certain criteria (see Attachment 2) that provide users and accreditation officials confi-dence in model validity and credibility when used by appropriately trained staff. 2.  AFAC SG. The AFAC SG is a Headquarters Air Force-chartered body that is chaired by the Director,Studies & Analyses, Assessments and Lessons Learned (HQ USAF/A9) and has membership consistingof representatives of Air Force analysis offices. The AFAC SG oversees AFSAT management and pro-vides supplemental guidance to the AFSAT Manager, model management organizations (MMO), andindividual model managers as required. The AFAC SG will designate a volunteer using organization, theMMO, to be responsible for management of each Air Force-owned AFSAT model in accordance with thisAFI. The AFAC SG will decide what models are in the AFSAT based on the process defined in Section Band the set of criteria in Attachment 2. Where there are multiple versions of a given model, the AFAC SGwill decide which version, if any, is in the AFSAT using this process. The AFAC SG will decide whatmodels are retired from the AFSAT based on the process defined in Section C and the set of criteria inAttachment 3. 3.  AFSAT Model Sponsor. Model sponsors are AFAC member organizations that nominate a model forentry into the AFSAT and continue as its advocate throughout the tenure of the model in the AFSAT. Nor-mally the model sponsor is either the AFAC member organization that provides the model manager (i.e.,the MMO), expends resources for model development, or is the primary model user. 4.  AFSAT Manager. HQ USAF/A9I is the AFSAT Manager and manages the AFSAT on behalf of theAFAC SG in accordance with the policies, processes, and procedures herein and any supplemental guid-ance provided by the AFAC SG. The AFSAT Manager will maintain a list of AFSAT models, theirMMOs, and individual Model managers and their contact information on the AFSAT section of the HQUSAF/A9 website at https://www.afsaa.hq.af.mil. The AFSAT Manager will coordinate with the AirForce Agency for Modeling and Simulation to ensure that the AFSAT is addressed in the Air Force Mod-eling and Simulation Resource Repository. AFI16-1003   17 FEBRUARY 200635.  MMOs and Model Managers. The MMO for each AFSAT model will designate in writing to theAFSAT Manager one or more specific individuals to be the model manager, responsible for managementof the AFSAT model in accordance with this instruction. The MMO will update this information to theAFSAT Manager when changes occur. Model managers will be cognizant of the AFSAT model entry cri-teria listed in Attachment 2 in the course of managing and enhancing their models, recognizing that adeterioration of an AFSAT model’s status relative to the entry criteria could undermine the justificationfor the model to be in the AFSAT and could result in a decision to retire it based on the process outlinedin Section C. 6.  AFSAT Model Users.  6.1.  Prospective users of AFSAT models should contact the appropriate model manager for informa-tion regarding model availability, performance, and user requirements. A list of AFSAT model man-agers and their contact information is maintained by the AFSAT Manager on the AFSAT section of theHQ USAF/A9 website (https://www.afsaa.hq.af.mil). 6.2.  Use of AFSAT models by AFAC organizations to conduct analysis is strongly encouraged froman Air Force M&S policy and an Air Force investment strategy viewpoint. Sponsors, users, and prac-titioners of analyses performed using non-AFSAT models should be prepared to defend investmentsin other models in functional Air Force corporate investment reviews and be aware that the analysismay be subject to increased scrutiny. 6.3.  The selection and use of an AFSAT model for an analytic task does not relieve the using organi-zation of the responsibility for accrediting the model for the specific intended use in accordance withAFPD 16-10, Modeling & Simulation (M&S) Management and AFI 16-1001, Verification, Validation,and Accreditation (VV&A). Section B—AFSAT Model Entry Policies, Processes and Procedures 7.  Model Entry Nomination. The sponsoring organization (model sponsor) must nominate a candidatemodel for AFSAT entry to the AFSAT Manager (HQ USAF/A9I) in writing. The candidate model willthen be evaluated for AFSAT entry using the process described in paragraphs 8.-11. and illustrated inAttachment 4. Note that Attachment 4 is a simplified illustration of the model entry process and doesnot cover the detailed procedures prescribed in paragraphs 8.-11.. 8.  Model Pre-Screening. 8.1.  The model sponsor will submit a model pre-screening package (MPSP) to the AFSAT Manager(for required MPSP contents, see Attachment 5). 8.2.  The AFSAT Manager will evaluate the MPSP against the mandatory AFSAT model entry criteria(Attachment 2). 8.3.  The AFSAT Manager will estimate the resources required to complete the formal evaluationdescribed herein in terms of people, time, and dollar cost, to include estimating the size and makeup(organizational membership) of the formal model evaluation team (MET). 8.4.  The AFSAT Manager will endeavor to complete the model pre-screening evaluation (paragraph8.2.) and MET resources estimate (paragraph 8.3.) in less than two months total. 8.5.  The model sponsor will brief the candidate model to the AFAC SG. 4AFI16-1003   17 FEBRUARY 20068.6.  The AFSAT Manager will brief the results of the pre-screening and the resources required for afull evaluation to the AFAC SG and either will recommend rejection of the candidate model for theAFSAT or formation of a MET and continuation of the model evaluation process. 8.7.  The AFAC SG will decide whether to reject the candidate model for the AFSAT or to approveformation of a MET to continue the model evaluation process. 9.  MET Formation and Preparation. 9.1.  The AFSAT Manager will lead and coordinate the formation and preparation of the MET. Themodel sponsor will also be a member of the MET. 9.2.  With the exception of the AFSAT Manager and the model sponsor, participation in the MET byAFAC member organizations is voluntary. The AFSAT Manager will recommend the organizationalmakeup of the MET team to the AFAC SG for its approval 9.3.  Each MET member organization will be responsible for providing the resources required for theirMET member to participate in the candidate model evaluation. 9.4.  The MET will endeavor to complete its review in three months or less. 9.5.  The MET will review the MPSP. 9.6.  The MET will hold an internal “calibration meeting” to discuss MET purpose, AFSAT entry cri-teria, and to formulate questions that must be answered. 9.7.  The MET will present its questions and issues to the model sponsor. 10.  Candidate Model Presentation & Evaluation. 10.1.  The model sponsor will present the case to the MET for AFSAT entry. The presentation mustinclude each of the mandatory AFSAT model entry criteria (Attachment 2), a model demonstration,studies and associated results using the candidate model, current and prospective users, user testimo-nials, model verification and validation (V&V) information, and the model user support plan. 10.2.  The MET will evaluate the candidate model against each mandatory AFSAT entry criterion(Attachment 2). 10.3.  The MET will present the results of the model evaluation to the model sponsor and solicit feed-back. 11.  AFAC SG Model Entry Decision. 11.1.  The MET will prepare and present a final briefing on the results of the model evaluation and theMET’s recommendation to the AFAC SG. 11.2.  The AFAC SG will decide whether to admit the candidate model to the AFSAT. 11.3.  If the AFAC SG decides not to admit a candidate model to the AFSAT, the AFAC SG meetingminutes will document the rationale for that decision. 11.4.  If, within three months of a non-admission decision by the AFAC SG, the model sponsor makeschanges to the model and re-nominates it for AFSAT entry, the model entry process starting with para-graph 10.1. through paragraph 11.2. must be repeated. If more than three months passes fromAFI16-1003   17 FEBRUARY 20065non-admission decision to re-nomination for AFSAT entry, the entire model entry process must berepeated starting with paragraph 8.1. Section C—AFSAT Model Retirement Policies, Processes and Procedures. 12.  Biennial AFSAT Model Review. Every two years the AFSAT Manager will conduct a review of thelatest officially released versions of the models in the AFSAT and based on this review prepare a ModelRetirement Candidate List (MRCL). Reasons for placing an AFSAT model on the MRCL are listed inAttachment 3. When releasing new versions of models currently in the AFSAT, model managers andmodel sponsors should be mindful not to degrade their model’s status relative to the criteria in Attach-ment 3. The AFSAT Manager will inform model sponsors when their models are on the MRCL. TheAFSAT Manager will annotate the MRCL with the model sponsors’ positions on the proposed retirementof their models from the AFSAT. 13.  Biennial Model Retirement Recommendation. The AFSAT Manager will recommend actionsindicated by the biennial review to the AFAC SG. Model sponsors who disagree with retiring their modelsfrom the AFSAT can make their case to the AFAC SG. 14.  Out-of-Cycle Model Retirement Nomination, Review and Recommendation.  14.1.  Model sponsors may at any time nominate their model to be retired from the AFSAT to theAFSAT Manager. In such cases, the AFSAT Manager will conduct an out-of-cycle review of themodel nominated for retirement. 14.2.  Based on this review, the AFSAT Manager will recommend retirement or retention of the modelto the AFAC SG. 15.  Model Retirement Decision. The AFAC SG will decide to retire or retain AFSAT models recom-mended for retirement by the AFSAT Manager whether based on the biennial review or an out-of-cyclereview. The AFAC SG, may, at its discretion, not take an immediate decision, but instead direct the forma-tion of a MET to conduct a formal model evaluation and make a retirement or retention recommendationback to the AFAC SG for subsequent decision. 16.  Form Adopted. AF IMT 847, Recommendation for Change of Publication. JACQUELINE R. HENNINGSEN,  PhD, SES Director, Studies & Analyses, Assessments and Lessons Learned 6AFI16-1003   17 FEBRUARY 2006Attachment 1   GLOSSARY OF REFERENCES AND SUPPORTING INFORMATION References DODD 5000.59, DoD Modeling and Simulation (M&S) Management, 4 January 1994 DOD 5000.59-M, DoD Modeling and Simulation (M&S) Glossary, January 1998 DODI  5000.61,  DoD  Modeling  and  Simulation  (M&S)  Verification,  Validation,  and  Accreditation(VV&A), 13 May 2003 AFPD 16-10, Modeling and Simulation (M&S) Management AFI 16-1001, Verification, Validation and Accreditation (VV&A) AFI 16-1002, Modeling and Simulation (M&S) Support to Acquisition AFI 33-202, Volume I, Network and Computer Security AFMAN 37-123, (will convert to 33-363), Management of Records Abbreviations and Acronyms AF—Air Force AFAC—Air Force Analytic Community AFB—Air Force Base AFCA—Air Force Communications Agency AFI—Air Force Instruction AFMAN—Air Force Manual AFPD—Air Force Policy Directive AFSAT—Air Force Standard Analysis Toolkit DC—District of Columbia DOD—Department of Defense DODD—Department of Defense Directive DODI—Department of Defense Instruction HQ—Headquarters IL—Illinois IMT—Information Management Tool IPT—Integrated Process Team MET—Model Evaluation Team MMO—Model Management Organization AFI16-1003   17 FEBRUARY 20067MPSP—Model Pre-Screening Package MRCL—Model Retirement Candidate List M&S—Modeling and Simulation NEWC—New and Emerging Warfighter Capabilities OPR—Office of Primary Responsibility PhD—Doctor of Philosophy RDS—Records Disposition Schedule SAF—Secretary of the Air Force SES—Senior Executive Service SG—Steering Group USAF—United States Air Force V&V—Verification and Validation VV&A—Verification, Validation and Accreditation WWW—Worldwide Web Terms Accelerated Acquisition M&S Thrust—The M&S Thrust that encompasses M&S focused on reducingthe time and resources required to provide material solutions to the warfighter, including support fordesign and development, testing, certification, and logistics and maintainability across the lifecycle of asystem. Accreditation—Official determination that a model or simulation is acceptable for use for a specificpurpose. Air Force Standard Analysis Toolkit—The standard toolkit of models used by the AFAC to aid inshedding light on Air Force problems, answering senior decision maker questions, and analyzingalternative systems and courses of action. Campaign Model—A model that attempts to capture all important aspects of aerospace power over theduration of a conflict across an entire theater or theaters of operation in a force vs. force campaign lengthscenario. Configuration Management—Application of technical and administrative direction and surveillance toidentify and document the functional and physical characteristics of a model or simulation, controlchanges, and record and report change processing and implementation status. Engagement Model—A model that provides measures of effectiveness at the system level ofrepresentation by evaluating system effectiveness against enemy systems in a one-on-one or few-on-fewcombat scenario. Integrated Process Team—A means to achieve concurrent engineering. They are multidisciplinaryteams consisting of representatives from all relevant disciplines. M&S Thrust—The Air Force organizes its M&S activities into four thrusts or areas of interest:8AFI16-1003   17 FEBRUARY 2006Warfighter Readiness, Accelerated Acquisition, New and Emerging Warfighter Capabilities, and M&SFoundations. M&S Thrusts marshal similar elements into cohesive, synergistic groupings. They provide amanageable mechanism for identifying M&S requirements while avoiding overlap, duplication, gaps andseams. M&S Foundations Thrust—The M&S Thrust that encompasses M&S tools and technologies needed toimprove the usefulness, productivity, scalability, or efficiency of M&S from across all of the Thrusts,including information technology, architectures, databases, standards, inter-operability,inter-connectivity, and consistent synthetic environments. Mission Model—A model that captures one or more interacting aspects of aerospace power during thecourse of representing an aerospace mission or missions by evaluating mission effectiveness againstenemy forces in a few-on-few or many-on-many combat scenario. Model—A physical, mathematical, or logical representation of a system entity, phenomenon, or process. Model User Support Plan—The model sponsor’s plan for supporting users of the model if it is admittedto the AFSAT. New and Emerging Warfighter Capabilities M&S Thrust—The M&S Thrust that encompassessupport for the formulation, exploration and evaluation of new and emerging warfighter capabilitiesthrough analysis, wargaming, and warfighting experimentation. New and Emerging Warfighter Capabilities M&S Thrust Integrated Process Team—The IntegratedProcess Team associated with the NEWC Thrust. Each M&S Thrust has an associated Thrust IPT: amultidisciplinary body that develops and implements crosscutting standards, resource strategies, andmodernization programs requiring an overarching integration process. Simulation—A method for implementing a model over time for the purpose of testing, analysis, ortraining. Validation—Rigorous and structured process of determining the extent to which M&S accuratelyrepresents the intended “real-world” phenomena from the perspective of the intended M&S use. Verification—Process of determining that M&S accurately represents the model developer’s conceptualdescription and specifications. Warfighter Readiness M&S Thrust—The M&S Thrust that encompasses support for improvedwartime decision-making, skills, and processes, including exercises, operational training, missionrehearsal, operational decision support, and concept development. AFI16-1003   17 FEBRUARY 20069Attachment 2   AFSAT MODEL ENTRY CRITERIA A2.1.  Does the candidate model provide data, answers, or insights that address a critical Air Forceanalytic capability?  A2.1.1.  Does the model provide a capability not currently in the toolkit? A2.1.2.  For what studies has the model been used? A2.1.3.  What Air Force-level decisions has the model supported or impacted? A2.1.4.  Do the model's capabilities overlap those of other models in the toolkit? A2.1.5.  Could this model replace a current toolkit model? A2.1.6.  What level of analysis does this model support (campaign, mission, engagement, other)? A2.1.7.  Does the analysis supported by this model impact a significant segment of the AFAC? A2.2.  Does the candidate model have adequate documentation?  A2.2.1.  Is there enough information for the evaluation team to knowledgeably evaluate the model? A2.2.2.  Is there enough documentation for an analyst to use the model within its valid bounds? A2.2.3.  Does the analyst’s or user’s manual describe the major model algorithms, algorithm and datarelationships, input data requirements, and output data? A2.2.4.  Are there sample input-output data files and does the documentation describe how to orga-nize, analyze and transform the model output into credible, actionable information? A2.3.  Is there a functioning and documented model configuration management process?  A2.3.1.  Is there a process for identifying, prioritizing, and funding model upgrades and corrections? A2.3.2.  Is there a process for notifying users about model bugs, corrections, changes, developments,and plans for future modification or development? A2.3.3.  Are there Version Description Documents? A2.3.4.  Is there a Configuration Control Board? A2.4.  Is there support to the using community?  A2.4.1.  Are there regularly scheduled Users’ Group meetings? A2.4.2.  Is there ready access to the model developer and maintainer for questions and problems? A2.4.3.  Is there a user training program or plan? A2.4.4.  Are users notified of bugs, changes, developments, and plans for future modification ordevelopment? A2.4.5.  Are the data needed to run the model available to the AFAC? A2.4.6.  If data are provided to users, are the sources documented? 10AFI16-1003   17 FEBRUARY 2006A2.5.  Is the candidate model readily usable?  A2.5.1.  Are the time and resources required to modify the source code reasonable? A2.5.2.  Are the time and resources required to create a scenario, enter data, process data, make modelruns, and analyze the results reasonable? A2.5.3.  Once a scenario has been run, is the time needed to run excursions off the baseline run rea-sonable? A2.5.4.  Are there baseline test cases that produce expected results, and do they cover the operationaldomain of the model? A2.5.5.  Does the model allow sensitivity analysis across a reasonable range of key inputs? A2.5.6.  Is the cost of the model and required supporting software appropriate for the level of analy-sis? A2.5.7.  Does the model run on a wide variety of standard platforms? A2.5.8.  Can the model easily operate in a classified environment? A2.5.9.  Does the user-interface minimize data errors and include adequate error-checks? A2.5.10.  Are runtime errors clearly identified and easily fixed? A2.5.11.  Are there intermediate results to aid in error isolation and analysis? A2.5.12.  Is the output well organized and easy to interpret and analyze? A2.5.13.  Can the user easily modify data output, display, and post processing to help the analyst gainan understanding of the underlying model outcomes and establish transparent, traceable cause andeffect relationships? A2.5.14.  Can the user trace the logic flow and behavior of key entities? A2.6.  Is there a V&V foundation available for review?  A2.6.1.  Is there enough V&V documentation to show what has been done so far? A2.6.2.  Is there a documented V&V plan? A2.6.3.  Are the model's assumptions, algorithms, and modeling approach appropriate? A2.6.4.  Are the model's critical entities and elements represented at a reasonable level of fidelity,detail, and completeness? A2.6.5.  Are the model's logic and representations accepted by subject matter experts? A2.6.6.  Is there a solid basis in theory and experimental data underlying the modeling approach? A2.6.7.  Is there internal validity, i.e., is the model consistent and reliable across runs? A2.6.8.  Are data consistent throughout the model? A2.6.9.  Are model-resident data traceable to accepted lower-level models, standard data sources, orfirst principles? A2.6.10.  Has the AFAC demonstrated acceptance of the model's results? AFI16-1003   17 FEBRUARY 200611A2.6.11.  Have the model results been validated against historical or physical test results? A2.6.12.  Are the bounds of the model's domain defined, and is the model accurate across its domain? A2.7.  Have model security vulnerabilities and dependencies been addressed in accordance withAFI 33-202, volume I, Network and Computer Security? A2.7.1.  If to be installed on a network, has the model or simulation been through a DOD-approvedsecurity review for vulnerabilities? A2.7.2.  Are identified vulnerabilities made known to the user community? A2.7.3.  What patches, service packs, or updates are required? A2.7.4.  Is there a system for informing the user community about necessary updates? A2.7.5.  Are there limitations on the distribution of model software (e.g., classification, open sourcelicensing, network vulnerabilities)? A2.7.6.  Have all necessary executables, registry settings, and software dependencies been madeknown to the user community? A2.7.7.  What Open Source or commercial-off-the-shelf software packages are required or recom-mended to run the model? A2.7.8.  What is the cost to use the model? 12AFI16-1003   17 FEBRUARY 2006Attachment 3   AFSAT MODEL RETIREMENT CRITERIA A3.1.  The model can be replaced by a new, better AFSAT model. A3.2.  The model does not meet the mandatory AFSAT model entry criteria (Attachment 2). A3.3.  The model is no longer an Air Force standard for use in Analyses of Alternatives and otherstudies supporting senior decision-makers. A3.4.  The model has become unusable or is not being used for Air Force analyses.  A3.5.  The model has become cost-prohibitive to own and use.  A3.6.  The model management organization has resigned and a replacement cannot be found. AFI16-1003   17 FEBRUARY 200613Attachment 4   AFSAT MODEL ENTRY PROCESS DIAGRAM  14AFI16-1003   17 FEBRUARY 2006Attachment 5   MODEL PRE-SCREENING PACKAGE CONTENTS A5.1.  Description of model, model capabilities, past uses, model history. A5.2.  List of current model users and model uses. A5.3.  Self-evaluation against AFSAT criteria. A5.4.  User’s manual. A5.5.  List of all other available documentation. A5.6.  All V&V reports. 