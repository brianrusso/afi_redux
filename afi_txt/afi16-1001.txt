BY ORDER OF THE SECRETARY  OF THE AIR FORCE AIR FORCE INSTRUCTION 16-1001 22 JUNE 2016 Operations Support VERIFICATION, VALIDATION  AND ACCREDITATION (VV&A)  COMPLIANCE WITH THIS PUBLICATION IS MANDATORY ACCESSIBILITY:   Publications and forms are available on the e-Publishing website at  www.e-Publishing.af.mil RELEASABILITY:  There are no releasability restrictions on this publication  OPR:  AF/A3OT  Supersedes:  AFI16-1001, 1 June 1996  Certified by: AF/A3O  (Maj Gen Scott D. West) Pages: 23    This publication implements DoDI 5000.61, DoD Modeling and Simulation (M&S) Verification, Validation,  and  Accreditation,  and  AFPD  16-10,  Modeling  and  Simulation,  by  establishing policy, procedures, and responsibilities for the VV&A of Air Force- owned or -managed models and simulations.  This publication applies to the Regular Air Force, Air Force Reserve, and Air National  Guard.    Ensure  that  all  records  created  as  a  result  of  processes  prescribed  in  this publication are maintained IAW Air Force Manual (AFMAN) 33-363, Management of Records, and  disposed  of  IAW  the  Air  Force  Records  Disposition  Schedule  (RDS)  in  the  Air  Force Records  Information  Management  System  (AFRIMS).    Refer  recommended  changes  and questions  about  this  publication  to  the  Office  of  Primary  Responsibility  (OPR)  using  the  AF Form  847,  Recommendation  for  Change  of  Publication;  route  AF  Forms  847  from  the  field through to  AF/A3OT  Workflow (usaf.pentagon.af-a3.mbx.a3ot-workflow@mail.mil) 1480  Air  Force  Pentagon, Washington, DC 20330-1480.  This publication may be supplemented at any level, but all direct supplements must be routed to the OPR of this publication for coordination prior to certification and  approval.    Note  that  to  avoid  confusion,  the  acronym  “LVC-OT”  will  be  used  to  refer  to Training  and  “OT”  by  itself  refers  to  Operational  Testing.    The  authorities  to  waive  wing/unit level  requirements  in  this  publication  are  identified  with  a  Tier  (“T-0,  T-1,  T-2,  T-3”)  number following the compliance statement. See AFI 33-360, Publications and Forms Management, for a  description  of  the  authorities  associated  with  the  Tier  numbers.    Submit  requests  for  waivers through the chain of command to the appropriate Tier waiver approval authority, or alternately, to the publication OPR for non-tiered compliance items.  National Guard Bureau is considered a Major Command (MAJCOM) for the purposes of this instruction’s Tier authorities.  Waivers to functional  chain  of  command the  appropriate or 2 AFI16-1001  22 JUNE 2016 mandates  involving  the  acquisition  program  execution  chain  are  processed  in  accordance  with the  acquisition  chain  of  authority  as  specified  in  AFI  63-101/20-101,  Integrated  Life  Cycle Management. SUMMARY OF CHANGES This document has been substantially revised and must be completely reviewed.  Major changes include  changing  the  Air  Force  M&S  VV&A  policy  approval  authority  from  Assistant  Vice Chief of Staff (AF/CVA) to Deputy Chief of Staff, Operations (AF/A3), replacing all references to Headquarters Air Force Directorate of Modeling, Simulation, and Analysis (HQ USAF/XOM) with  AF/A3OT  as  appropriate,  and  updating  the  language  so  that  it  better  aligns  with  DoDI 5000.61,  DoD  Modeling  and  Simulation  Verification,  Validation,  and  Accreditation,  and  DoDI 5000.70, Management of DoD Modeling and Simulation (M&S) Activities.  Section A— General  1. 2.  Applicability. ..........................................................................................................   Background. ............................................................................................................  Section B— Roles and Responsibilities for V  3. 4.  HQ USAF Responsibilities. ....................................................................................   MAJCOM Commander Responsibilities. ...............................................................  Section C— VV&A Framework, Functional Roles, and Processes  5.  VV&A Framework. ................................................................................................  Figure  1.  M&S Options and VV&A Steps. ............................................................................  6.  Functional Roles within the Air Force VV&A Process. .........................................  Table  1.  VV&A Roles & Documentation Responsibilities ..................................................  7. 8. 9.  VV&A Process .......................................................................................................   VV&A Documentation. ..........................................................................................   VV&A Repository. .................................................................................................  10.  Multi-Model or Federated Architectures. ...............................................................  Attachment 1— GLOSSARY OF REFERENCES AND SUPPORTING INFORMATION  2 2 3 4 4 6 6 6 7 8 9 13 17 18 18 20  Section A—General 1.  Applicability.  This  instruction  applies  to  all  Air  Force  (owned  or  managed)  models  and simulations  that  qualify  as  federation  elements,  common-use,  general-use,  or  joint  modeling  & AFI16-1001  22 JUNE 2016 3 Simulation  (M&S)  as  defined  in  the  DoD  M&S  Glossary.    MAJCOMs,  Field  Operating Agencies (FOAs), and Direct Reporting Units (DRUs) will establish verification, validation, and accreditation  (VV&A)  requirements  and  procedures  for  command-owned  models  and simulations that do not fit into one of these use categories. 2.  Background.  Before  decision  makers  vest  their  confidence  in  M&S  results  used  to  make decisions  involving  large  costs  or  human  lives,  such  confidence  must  be  justified.    VV&A  are processes  by  which  M&S  content  and  quality  are  investigated,  documented,  and  authenticated. This  instruction  is  based  on  the  concept  that  verification  and  validation  (V&V)  will  be  a continuous process throughout a model’s life cycle.  Air Force model V&V plans will emphasize an  incremental  "building  block"  approach  where  different  V&V  activities  are  sponsored  by individual users to support their specific accreditation needs.  These V&V results are maintained in  locations  available  to  all  model  users,  such  as the  DoD  M&S  Catalog.    This  approach,  over time, produces  an in-depth  examination of the model, with  the V&V  costs being shared across the  model’s  entire  user  community.    Accreditation  is  the  final  step  that  allows  a  validated  and verified model to be used for a particular application or period of time. 2.1.  A  systematic  V&V  plan  will  be  an  integral  part  of  any  Air  Force  M&S  development, enhancement,  maintenance,  or  upgrade  activity.  V&V  will  also  be  accomplished  in  concert with, and as part of, overall M&S configuration management actions. 2.2.  Air  Force  models,  simulations,  and  associated  data  used  to  support  DoD  processes, products, and decisions shall undergo V&V throughout their lifecycles. 2.3.  Air  Force  M&S  applications  will  be  accredited  for  their  intended  purpose  when supporting  major  DoD  decision-making  organizations  or  processes,  joint  training,  and  joint exercises.    All  executed  V&V  activities  will  support  the  model  acceptance/accreditation requirements defined by the accreditation authority. 2.4.  Air  Force  agencies  using  M&S  owned  by  other  DoD  components  will  adhere  to  the terms  and  conditions  specified  in  any  memorandum  of  agreement  (MOA)  releasing  the model  for  Air  Force  use.  Unless  otherwise  specified,  the  Air  Force  using  agency  will  be responsible for accomplishing model V&V activities according to model owner, MAJCOM, or  (if  applicable)  Air  Force  guidance,  whichever  is  the  most  appropriate  for  the  intended model  use  if  not  already  part  of  an  existing  VV&A  approval.    Note  that  a  MOA  is  not required if the other component does not have release restrictions imposed on the model. 2.5.  The Air Force agency that is responsible for a contractor or Federally Funded Research and  Development  Center  (FFRDC)  developed  model  and/or  simulation  (either  new  major model development or enhancements) will ensure that V&V requirements are accomplished. 2.6.  Model  managers  and  developers  are  responsible  for  ensuring  compliance  with  the appropriate V&V requirements when an M&S configuration changes. 2.7.  If  applicable,  V&V  activities  will  include  assessments  of  the  representations  of concepts,  tactics,  forces,  processes,  and  doctrine  from  all  protagonists’  perspectives.  The authoritative source for threat models and data is the Defense Intelligence Enterprise (DIE). The  Defense  Intelligence  Agency  (DIA),  Missile  and  Space  Intelligence  Center  (MSIC), National  Air  and  Space  Intelligence  Center  (NASIC),  National  Ground  Intelligence  Center (NGIC), and the Office of Naval  Intelligence (ONI) are primary participants in the DIE for authoritative threat models and data. 4 AFI16-1001  22 JUNE 2016 2.8.  The VV&A of a federation of M&S will comply with VV&A policy for each individual M&S,  but  will  also  consider  overall  system  compliance,  compatibility,  and  interoperability requirements.    The  VV&A  of  a  federation  of  systems  will  ensure  credible  results  of  the integrated system as a whole. 2.9.  Data used in models and simulations will be verified, validated, and certified for use in specific applications. 2.10.  The M&S developed as an integral part of a weapon system will be managed according to the policies addressing the larger system.  However, the VV&A and requirements portions of this instruction are mandatory for ensuring the internal integrity of such M&S. 2.11.  Models  developed  and  maintained  by  a  designated  authoritative  source  that  are adopted  for  use  by  other  systems  will  not  require  any  additional  VV&A  if  the  model’s implementation meets the authoritative source’s accreditation constraints. 2.12.  Test  and  Evaluation  (T&E)  M&S  is  a  foundational  element  of  Integrated  Life  Cycle Management.    Effective  use  of  M&S  for  T&E  over  the  life  cycle  of  a  system  can substantially  reduce  program  risk  and  has  benefits  for  Program  Managers,  Systems Engineers,  decision-makers,  and  system  users.    The  purpose  of  T&E  modeling  and simulation is to: provide an increase in confidence level; provide a decrease in field test time and costs; increase amount of data collected for pre-test predictions and post-test validation; support test control and promote safety; and simulate non-testable events and scenarios. Section B—Roles and Responsibilities for V &V Management  3.  HQ USAF Responsibilities. 3.1.  The  appropriate  HQ  USAF  Deputy  Chief  of  Staff  (DCS)  or  Assistant  Chief  of  Staff (ACS)  will  approve  the V&V  report  that  accompanies  the  release  of  Air  Force  models  and databases within their functional areas which meet the following two conditions: 3.1.1.  The M&S will be used to support joint exercise or training activities. 3.1.2.  The M&S portrays Air Force capabilities, force structure, doctrine, or tactics when used in these activities. 3.2.  AF/A3 is the approval authority for M&S VV&A policy.  AF/A3 will coordinate with AF/A9 for Decision Support VV&A and with SAF/AQ for Life Cycle Management VV&A. 3.2.1.  AF/A3W,  Director  of  Weather,  as  the  designated  Air  and  Space  Natural Environment Modeling and Simulation Executive Agent  (ASNE MSEA) will determine resources, roles, and responsibilities for ASNE related VV&A per AFMD 1-54, Deputy Chief of Staff, Operations. 3.3.  AF/A2  will  determine  the  assignment  of  V&V  manager  responsibilities  to  the appropriate Air Force intelligence entity  for threat  models or simulations owned by the  Air Force.    AF/A2  (or  appropriate  DIE  organization)  must  be  consulted  with  to  determine appropriate intelligence data sources and to ensure that threat portrayals  conform to current assessments. AFI16-1001  22 JUNE 2016 5 3.4.  AF/A9  will  manage  decision  support  M&S  and  analysis  policy  and their implementation.  In compliance with overall DoD and AF M&S policy, AF/A9 will develop VV&A  requirements  for  M&S  used  in  decision  support  and  all  planning,  programming, budgeting, and execution process supporting analyses. 3.5.  SAF/AQ  is  responsible  for  Life  Cycle  Management  and  Acquisition  M&S  policy.  SAF/AQ will support early acquisition VV&A of models and simulations used in support of acquisition programs, and integrates with AF/A2 (or appropriate DIE organization) to ensure appropriate  intelligence  data  sources  and  threat  models  or  simulations  are  used  in  weapon system acquisitions. 3.6.  AF/TE  advises  Air  Force  leadership  on  the  use  of  M&S  in  T&E  and  develops  policy and  guidance  for  its  use.    AF/TE  will  support  and  oversee  VV&A  in  accordance  with  AFI 99-103,  Capabilities-Based  Test  and  Evaluation,  and  consistent  with  the  T&E  V&V checklist in the DoD VV&A Recommended Practices Guide (RPG). 3.7.  HAF 2-Letters  serve as the final validation authority for representations in common-use and  general-use  models,  simulations,  and  associated  data,  of  the  DoD  Component’s  forces, processes, characteristics, and performance capabilities within their area of responsibility.  In addition HAF 2-Letters shall: 3.7.1.  Be  responsive  to  HAF  requests  to  ensure  Air  Force  forces,  processes, characteristics, and performance capabilities are appropriately represented in DoD forums and exercises. 3.7.2.  When operating as approved by USD(AT&L) as a designated MSEA (e.g., Air and Space Natural Environment (ASNE)): 3.7.2.1.  Provide  domain  information  and  expertise  in  support  of  VV&A  activities, upon request. 3.7.2.2.  Ensure  data  quality  information  is  available  and  accessible  to  support  OSD and other DoD Component’s VV&A activities. 3.7.2.3.  Establish  and  provide  reference  implementations  for  use  as  referent  and validation referent data within their areas of responsibility. 3.7.3.  Assign responsibilities to ensure that: 3.7.3.1.  Models,  simulations,  and associated data that are developed or modified on behalf of the Air Force are verified and validated throughout their lifecycles. 3.7.3.2.  As appropriate, models, simulations, and associated data that are used by the Air Force are accredited for a specific intended use. 3.7.3.3.  Resources  are  planned,  programmed,  and  budgeted  by individual organizations implementing verification, validation, and/or accreditation processes to support DoD processes, products, and decisions. 3.7.4.  Ensure  that  necessary  planning,  programming,  and  budgeting  resources  are provided and developed. 3.7.5.  Maintain specifications, standards, and other related standardization documents for VV&A. 6 AFI16-1001  22 JUNE 2016 3.7.6.  Encourage  participation technical  committees  of  government  and nongovernment  standards  bodies  and  forums  developing  VV&A  standards  and  in  the review and adoption of government and non-government standards for VV&A. in 3.7.7.  Ensure  coordination  with  AF/TE  and  appropriate  Operational  Test  Organizations for the VV&A of any M&S that is planned for T&E application. 4.  MAJCOM Commander Responsibilities. 4.1.  Establish  a  V&V  manager  for  each  command-owned  model  or  simulation  (per paragraph  6.3  below).  A  V&V  manager  may  be  responsible  for  more  than  one  model  or simulation.    Unless  otherwise  designated,  the  program  office  for  a  system  implementing models will be considered the owner of that model or simulation. 4.2.  Air  Force  organizations  designated  as  a  MSEA  will  have  both  Air  Force  and  DoD responsibility for V&V of the respective DoD application. 4.3.  Employ  models  from  authoritative  sources  to  the  maximum  extent  possible  where technically and fiscally feasible. 4.4.  Be prepared to  provide personnel  that can  serve on Technical  Review Working Group (TRWG)  teams  as  subject  matter,  problem  domain,  or  technical  experts  (including  model development, operation, and maintenance). 4.5.  Establish, as necessary, supplemental guidance and procedures that identify and manage the VV&A requirements for command operated models that do not qualify as common-use, general-use,  or  joint-use  M&S  as  defined  in  DoD  M&S  Online  Glossary.  This  will  include the  "threshold"  criteria  that  require  "prototype"  computer  code  be  treated  as  a  model  for V&V purposes. Section C—VV&A Framework, Functional Roles, and Processes  5.  VV&A Framework. 5.1.  M&S  requirements  developed  as  part  of  other  processes  (operational  test,  life  cycle management, decision support, training, etc.) will have varying levels  of VV&A  associated with the development and use of models for specific purposes. 5.1.1.  Verification  is  accomplished  by  identifying  and  eliminating  mistakes  in  logic, mathematics,  or  programming.  This  process  establishes  that  the  M&S  code  and  logic correctly perform the intended functions, and to what extent M&S development activities conform to state-of-the-practice software engineering techniques. 5.1.2.  The  validation  process  can  be  used  to  identify  model  improvements,  where necessary. It has two main components: structural validation, which includes an internal examination  of  M&S  assumptions,  architecture,  and  algorithms  in  the  context  of  the intended  use;  and  output  validation,  which  determines  how  well  the  M&S  results compare with the perceived "real world." 5.1.3.  The  accreditation  determination  considers  the  V&V  status  of  a  specific  model version,  its  data  support  (source,  quality,  and  verification)  and  the  analysts/users  that operate the model and interpret  its results.  The  accreditation authority is  the individual who is responsible and accountable for decisions or actions based upon the specific M&S AFI16-1001  22 JUNE 2016 7 usage. The decision to accredit a model or simulation rests solely with the accreditation authority. The accreditation authority determines the level of effort needed to support the accreditation  decision,  whether  it  consists  of  conducting  additional  V&V  activities  or simply  reviewing the  existing  M&S  documentation  and  past  VV&A  history. Accreditation  is  a  management  responsibility  of  the  requiring  agency,  assisted  by  the designated V&V agent. 5.2.  Figure  1  illustrates  the  associated  VV&A  steps  to  meet  an  M&S  requirement  based upon the existence and type of VV&A already accomplished for the application of that model or data for M&S.  Note that the diagram does not show the non-M&S methodology options (e.g., actual flight tests) since they do not require VV&A. Figure 1.  M&S Options and VV&A Steps.  5.3.  The  figure  shows  where  VV&A  occurs  within  the  overall  M&S  development  and integration process.  While the overall M&S process is out of the scope of this AFI, the broad aspects  of the major steps before and  after the  VV&A portion are included here to  provide context  and  the  differing  entry  and  exit  aspects  for  the  VV&A  portion  that  depend  on  the decisions made earlier in the process. 5.4.  The  first  step  of  the  overall  M&S  selection  process  begins  in  the  upper  left,  proceeds down along the left edge of the figure, then left to right and then back up, culminating with documentation.  Starting in the upper left, the first step is establishing a requirement followed by selecting the methodology to fulfill that requirement.  For the methodologies that include 8 AFI16-1001  22 JUNE 2016 M&S,  the  following  steps  are  to  first  identify  the  M&S  requirements  (reference  paragraph 7.1),  researching  the  availability  of  pre-existing  models  from  the  repositories  (reference paragraph 9), then selecting from the available M&S alternatives. 5.5.  The center of the figure depicts the four M&S VV&A options that depend on the chosen model option.  The four broad alternatives for M&S options are shown within the bracketed center portion of the figure: Use available as-is, accredit existing M&S for an alternative use, modify existing M&S, or develop new M&S.  The first two options of using available as-is and  accrediting  existing  M&S  for  an  alternative  use  have  greatly  reduced  verification  and validation  requirements  compared  to  the  other  two  alternatives,  but  will  still  have  some documentation requirements for accreditation (see paragraph 7.11).  In most cases, a simple face validation during the selection process establishes the applicability of the selected M&S, which  can  then  be  documented  in  the  Accreditation  Decision  by  the  cognizant  authority.  Note that there will be cases where there is no existing M&S to be used as-is or accrediting for this alternative use. 5.6.  The  top  two  (shown  unshaded  in  the  figure)  have  greatly  simplified  VV&A requirements due to the ability to leverage existing documentation.  The second two options (in  the  shaded  box)  will  have  to  follow  a  more  detailed  VV&A  process  as  shown  on  the bottom  row  of  the  figure  and  as  described  in  paragraph  7,  including  determining  the requirements  for  planning,  designing,  and  implementing  the  various  steps  to  complete  the V&V  process  and  necessary  documentation  to  support  the  Accreditation  Decision.  Appropriate reuse of existing M&S is encouraged in order to reduce the potential impacts to resources and schedules from the development process. 5.7.  The  accredited  M&S  is  then  integrated  into  the  application/simulation  in  a  way  that complies  with  the  Accreditation  Decision’s  conditions  (see  paragraph  7.10).    The  final remaining step is to properly document the M&S, which includes the VV&A documentation addressed in paragraph 8. 6.  Functional Roles within the Air Force VV&A Process. 6.1.  The  Air  Force  VV&A  process identifies  six  functional  roles  with  differing responsibilities during each phase of the VV&A  process.   The roles  are  Requiring Agency, Accreditation  Authority,  Accreditation  Agent,  V&V  Manager,  V&V  Agent,  and  Program Manager.    There  is  an  additional  optional  body,  the  Technical  Review  Working  Group, which  may  be  convened  as  required.    The  respective  roles  regarding  the  VV&A documentation  products  are  illustrated  in  Table  1,  VV&A  Roles  &  Documentation Responsibilities.    The  respective  tasks  are  described  in  greater  detail  in  the  rest  of  this instruction.    The  Requiring  Agency  may  also  be  labeled  as  the  User  or  M&S  Proponent  in other M&S documents.   Task Define M&S Requirements Acceptability Criteria Accreditation Plan V&V Plan V&V Implementation V&V Data V&V Report Lead Monitor Monitor Monitor Monitor Assist Assist Approve Lead Review Assist Assist Review Review Review Review Review Monitor Approve Monitor Monitor Monitor Monitor Lead Monitor Monitor Monitor Monitor Review Approve Approve Approve Approve Review Lead Lead Lead Perform 9 Program Manager/ Developer Assist Assist Assist Assist Assist Assist Assist   AFI16-1001  22 JUNE 2016  Table 1.  VV&A Roles & Documentation Responsibilities   Requiring Accreditation Accreditation V&V Agency Authority Agent Manager V&V  Agent Review Review Lead Perform Perform Monitor Approve Accreditation Assessment Accreditation Report Accreditation Decision M&S Catalog/ Repository Lead: Leads the task; normally involves active participation of others. Perform: Does the task; normally requires little active participation of others. Assist: Actively participates in the task. Monitor: Oversees the task but does not normally participate. Review: Reviews the results of the task and provides recommendations Approve: Decides when the task is satisfactorily completed and a new task may begin; Monitor Monitor Perform Assist         determines the future progress for the task.   6.2.  Depending  on  the  scope  and  complexity  of  the  model  as  determined  by  the  Requiring Agency,  the  V&V  roles  of  manager,  accreditation  authority,  accreditation  agent,  and verification/validation agent may be filled by the same individual or multiple personnel. At a minimum, the V&V agent and Accreditation agent should not be the same person, depending on available resources and if more than one person is filling these roles. 6.3.  Requiring Agency. 6.3.1.  Requiring  Agencies  are  normally  MAJCOMs,  or  the  organization  with  the validated  requirement  that  includes  M&S  capabilities.    Lead  Commands  will  be  the Requiring  Agency  for  the  operational  training  M&S  for  their  weapon  systems.    The Program  Manager  or  Operational  Test  Organization  is  the  Requiring  Agency  for  T&E M&S.      SAF/AQ  will  determine  the  Requiring  Agency  for  Integrated  Life  Cycle Management M&S.  AF/A9 will determine the  Requiring Agency  for Decision Support M&S.  AF/A3 is the final authority for determining the Requiring Agency for LVC-OT M&S. 10 AFI16-1001  22 JUNE 2016 6.3.2.  The following guidelines will be used to identify the Air Force organization with VV&A  management  responsibility  for  a  particular  model  or  simulation  that  does  not already have a designated model manager. 6.3.2.1.  For  models  or  simulations  under  development,  either  in-house  or  under contract  by  a  sponsoring  Air  Force  agency,  the  sponsoring  Air  Force  agency  is responsible. (T-1) 6.3.2.2.  For models or simulations  which do not  have a designated model  manager, and  are  operated  and  maintained  by  a  single  Air  Force  agency,  that  agency  is responsible. (T-1) 6.3.2.3.  For models or simulations  which do not  have a designated model  manager, and have multiple users or separate users and maintainers: 6.3.2.3.1.  If  a  configuration  management  or  users  group  exists,  the  agency chairing this group is responsible. (T-1) 6.3.2.3.2.  If  a  configuration  management  or  users  group  does  not  exist,  the predominant Air Force user is responsible. (T-1) 6.3.3.  The Requiring Agency will: 6.3.3.1.  Identify  the  Accreditation  Authority.    This  may  be  internal  to  the organization,  or  assigned  to  external  organizations  or  program  offices  depending  on the scope of the effort and requirements. (T-1) 6.3.3.2.  Define the M&S requirements for the model or simulation. (T-1) 6.3.3.3.  Maximize  use  of  existing  accredited  models  and  simulations  or modifications  of  existing  models  before  developing  new  models  to  maximize  M&S reuse. (T-1) 6.3.3.4.  Sponsor and/or fund development and implementation efforts for that M&S application. (T-1) 6.3.3.5.  In coordination with the Program Manager, establish security guidelines for the  protection  of  sensitive  or  classified  information  associated  with  the  models  and supporting documentation in accordance with existing security policy and guidance. 6.4.  Accreditation Authority. 6.4.1.  General  Officers  (GO)  or  Senior  Executive  Service  (SES)  personnel  or  their subordinate  staff  at  the  O-6/GS-15  level  who  manage  or  develop  the  M&S  shall  be  the Accreditation Authority for those particular models and/or simulations being used in that particular  effort.    For  T&E  M&S,  General  Officers  (GO)  or  Senior  Executive  Service (SES)  personnel  or  their  subordinate  staff  at  the  O-6/GS-15  level  shall  be  the Accreditation Authority for those particular models and/or simulations being used in that particular effort.  The Accreditation Authority will: 6.4.1.1.  Identify pertinent parameters and constraints that impact the V&V planning and  implementation  process,  including  M&S  acceptance  and  accreditation  criteria. (T-1) AFI16-1001  22 JUNE 2016 11 6.4.1.2.  Determine  the  need  to  form  a  TRWG  for  review  of  V&V  plan  and  results. (T-1) 6.4.1.3.  Select or approve personnel that are involved in the M&S VV&A activities; i.e., verification, validation, or accreditation agents, optional TRWG members, other subject matter experts (SME), etc.  (T-1) 6.4.1.4.  Approve and monitor the implementation of all V&V activities that directly support the upcoming accreditation decision.  (T-1) 6.4.1.5.  Ensure  completion  and  dissemination  of  appropriate  accreditation  reports.  (T-1) 6.4.1.6.  Be  responsible  for  funding  and  implementing  the  assessment  and  V&V activities supporting his/her specific model (application) accreditation.  (T-1) 6.4.2.  M&S  used  for  testing  must  have  an  Accreditation  Authority  approved  by  the intended user (PM or Operational Test Agency).  (T-1) 6.5.  Accreditation Agent. 6.5.1.  Serves  as  a  source  of  advice  and  expertise  to  the  accreditation  authority concerning VV&A issues. 6.5.2.  Assists  accreditation  authority  in  identifying  M&S  acceptance  and  accreditation criteria. 6.5.3.  Performs M&S accreditation assessment and determines any deficiencies between documented capabilities and accreditation requirements which require further V&V. 6.5.4.  Assists  accreditation  authority  in  determining  the  need  to  form  a  TRWG  and,  as the accreditation authority’s representative, chairing subsequent TRWG proceedings. 6.5.5.  Ensures, as the accreditation authority’s representative during the verification and validation planning and implementation process, that the approved accreditation plan will provide  sufficient  V&V  to  support  the  accreditation  decision  while  remaining  within accreditation authority-established constraints. (T-3) 6.5.6.  Prepares  accreditation  report  documentation  for  accreditation  decision,  and afterwards disseminates the completed accreditation report. 6.5.7.  Documents  M&S  application  accreditation  decisions  after  review  of  supporting accreditation reports. 6.6.  V&V  Manager.  Every  major  Air  Force  model  will  have  a  single  V&V  manager throughout its life cycle. (T-3)  Depending on model size and complexity, this function will be assigned to  the model  manager or to  the agency  with  model management  responsibility. For  new  models,  the  V&V  manager  will  be  identified  at  the  start  of  model  development activities. For existing models, the V&V manager will develop a time-phased plan to comply with these V&V responsibilities. (T-3)  The V&V manager for threat models or simulations will normally be the appropriate DIE entity per the Threat Modeling and Analysis Program. 6.6.1.  At any one point in time there can be only one clearly designated V&V manager for a  given model;  however, there is  no restriction to  the transfer of V&V management responsibility  between  organizations.  For  example,  the  developing  agency  could 12 AFI16-1001  22 JUNE 2016 simultaneously transfer both model management and V&V management responsibility to the model manager when delivering the completed model. 6.6.2.  Responsibilities of the V&V Manager include: 6.6.2.1.  Provides  expertise  on  current  and  previous  V&V  efforts  to  HQ  USAF  or MAJCOM, FOA, or DRU technical review committees. 6.6.2.2.  Establishes,  based  primarily  upon  input  from  the  user  community  and  in conjunction with the model manager, baseline V&V status for legacy models. 6.6.2.3.  Develops,  in  conjunction  with  the  model  manager,  a  long-range  plan  that prioritizes  V&V  activities  for  known  model  deficiencies  and  upcoming  model enhancements/upgrades. 6.6.2.4.  Coordinates  on maintenance, upgrade, and configuration changes. the  V&V  requirements  related to  proposed  model 6.6.2.5.  Maintains  a  repository  of  all  current  and  historic  V&V  information  on  the particular model or simulation and provides V&V status updates.  Users will be able to  access  the  information  via  the  M&S  Catalog  or  other  repository  that  meets  DoD requirements.  (T-3) 6.6.2.6.  Advocates for resources needed to  carry out  the previously described M&S V&V management responsibilities. 6.7.  V&V Agent. 6.7.1.  Serves  as  a  source  of  advice  and  expertise  to  the  accreditation  authority, accreditation agent, and V&V manager concerning V&V issues. 6.7.2.  Develops  a  plan,  including  resource  requirements,  that  addresses  the  V&V deficiencies identified by the accreditation agent while remaining within the accreditation authority-identified  constraints.  If  this  is  not  possible,  the  agent(s)  will  work  with  the accreditation  agent  to  develop  risk  reduction  and  V&V  plans  that  together  will  meet accreditation authority M&S acceptance criteria and constraints.  (T-3) 6.7.3.  Provides  a  suggested  list  of  TRWG  members  to  the  accreditation  authority  and accreditation agent, and actively participates in any subsequent TRWG meetings. 6.7.4.  Performs all V&V activities and prepares the final V&V report for submission to the accreditation agent and the model and/or simulation’s V&V manager.  (T-3) 6.8.  Program  Manager/Developer.  The  Program  Manager/Developer  funds  development of V&V (V&V plan, implementation, data, and report) and assists other functions during the respective  steps.    There  may  be  personnel  within  the  program  office  assigned  to  perform roles such as the Accreditation Authority or any others through V&V Agent.  The program office may even be designated the Requiring Agency for some models or applications.  Some of  the  key  input  the  Program  Manager  provides  during  the  VV&A  process  is  assessing  the impact  to  cost,  schedule,  and  performance  of  the  overall  program  on  the  various  VV&A options considered.  AFI16-1001  22 JUNE 2016 13 6.9.  V&V  Technical  Review  Working  Group.  This  working  group  is  formed  on  an  as-needed  basis  and  is  intended  to  develop  a  community  consensus  that  an  approved  V&V methodology  will  be  adequate  to  support  proposed  model  accreditation  decision,  within identified  constraints  and  associated  risk  mitigation  strategies.  This  group’s  membership  is tailored to the model and proposed application. Working group composition may include: 6.9.1.  Accreditation Agent 6.9.2.  Verification and Validation Agent(s) 6.9.3.  Model manager 6.9.4.  V&V manager (if different from model manager) 6.9.5.  MSEA (if V&V activities directly involve their problem domain) 6.9.6.  User's group chair (if applicable) 6.9.7.  Other optional) technical  cognizance (organizational) representatives (Membership 6.9.8.  Independent Technical Review representative (Membership optional) 6.9.9.  Data Source(s) Verification, Validation, and Certification (VV&C) representative (Membership optional) 6.9.10.  AF/A3OT  and  other  Service  representatives  (When  multi-Service  participation required) 6.9.11.  Other OSD representatives (When multi-Service participation required) 7.  VV&A Process 7.1.  Define  M&S  Requirements.  The  Requiring  Agency  and  Program  Manager/Developer (usually  the  responsible  study/project  team  lead)  first  establish  guidance  impacting  M&S support  for  a  given  project,  including  (but  not  limited  to)  available  manpower  and  funding resources;  project  constraints  (cost,  schedule,  performance);  requirements  that  will  be supported  using  M&S;  and  acceptability/accreditation  criteria including  pertinent accreditation criteria. 7.1.1.  Acceptability Criteria Development.  Acceptability criteria are the most important content  of  the  accreditation  plan  and  should  be  presented  as  minimum  criteria  for accreditation.  The requiring agency appoints an accreditation agent to establish a set of acceptability criteria to determine the suitability of the M&S for the intended use.  These acceptability  criteria  are  unique  to  each  problem,  intrinsically  linked  to  the  M&S requirement,  and  give  key  insights  to  potential  solutions.  Acceptability  criteria  are effectively a set of standards that a particular M&S must meet to be accredited for a given use.  These should be sufficiently developed to the level of detail necessary to meet the requirement (e.g., accurately represent a specific weapon’s fly out performance envelope and probability of kill for specific target types, or the circular error probable of a missile).  Examples of high-level acceptability criteria to be used as a starting point are: 7.1.1.1.  The M&S fidelity and resolution are sufficient for the intended activity. 14 AFI16-1001  22 JUNE 2016 7.1.1.2.  The M&S is suitable for the overall intended use (e.g., training, explanatory, predictive). 7.1.1.3.  The  M&S  output/results  may  be  used  clearly,  adequately  and  appropriately to address the problem. 7.1.1.4.  The  levels  of  force  structure  and  interaction  have  sufficient  fidelity  and resolution. 7.2.  Existing  M&S  Assessment.  The  accreditation  agent  identifies  the  particular  model(s) and/or simulation(s)--including requisite modifications or enhancements--from available Air Force/  DoD  M&S  repositories  that  appear  to  meet  the  parameters.    The  accreditation  agent will  assess  the  model  or  simulation  to  determine  if  its  proposed  usage  falls  within  a previously  validated  and  verified  application  domain  and  whether  any  V&V  deficiencies must  be  corrected  for  the  model  or  simulation  to  meet  the  accreditation  authority’s acceptability  criteria.    (T-3)  A  proposed  model  or  simulation  may  be  accredited  if  its documented  V&V  history  sufficiently  supports  specified  acceptance  and  accreditation criteria. 7.3.  Accreditation  Plan  Development.    The  accreditation  agent  reviews  the  configuration management procedures, M&S documentation, and the V&V findings (if they exist) that will be  used  to  make  the  determination  on  accreditation.  These  items  become  a  part  of  the accreditation  plan.    All  information  considered  in  the  accreditation  process  must  be documented in  the accreditation report; this report is  the responsibility of the Accreditation Agent  and  is  produced  with  the  assistance  of  the  Program  Manager/Developer.  (T-3)  A sample format for the plan is available in the DoD VV&A RPG. 7.4.  V&V  Plan  Development.  Verification  and  validation  agent(s),  based  on  accreditation acceptance criteria identified during the accreditation agent’s M&S assessment, will develop a  plan  that  ensures  sufficient,  documented  model  V&V  to  support  accreditation  acceptance criteria. (T-2) A sample format for the plan is available in the DoD VV&A RPG. 7.4.1.  The DoD MSEA will be consulted if V&V activities will be performed on portions of  the  model  or  simulation  that  lie  within  their  problem  domain  (e.g.,  weather  or atmospheric effects should be coordinated with the ASNE MSEA). 7.4.2.  The V&V plan will identify data sources to obtain verified, validated, and certified input  data.    (T-3)    Scenario  data--reflecting  current  threat  representations--will  be obtained  from  or  coordinated  with  the  appropriate  intelligence  source(s).    Designated MSEAs or other authoritative sources data will be considered validated and verified when used in accordance with their guidance.  Otherwise, the V&V Manager is responsible for coordinating the data V&V as described in the VV&A RPG. 7.4.3.  For non-government owned models or for new model starts, the plan must include establishment  and  operation  of  V&V  management  mechanisms  and  responsibilities  by the accreditation sponsor. 7.4.4.  The  V&V  plan  will  identify  and  source  estimated  planning  and  implementation manpower/funding. (T-3) 7.5.  V&V Technical Review Working Group Review.  Upon completion of V&V activities, the  committee  can  be  convened  to  review  actual  versus  planned  V&V  implementation  and AFI16-1001  22 JUNE 2016 15 results;  review  or  perform  a  risk  assessment  (for  any  unaccomplished  V&V  activities),  and provide a written summary of their findings and recommendations to the V&V agents.  The V&V  agents  will  then  prepare  the  V&V  report  that  summarizes  overall  findings  and recommendations. (T-3) 7.6.  V&V  Implementation.    V&V  can  be  an  iterative  process  as  the  models  and  data  are refined to meet the requirements.  Testers (developmental and operational) are expected to be involved  early  in  the  process,  including  the  Operational  Test  Organizations  (OTOs),  if  the subsequent  T&E  results  are  to  be  accepted.    VV&A  activities  and  findings  will  be documented in  the following acquisitions documents: System Engineering Plan (SEP), Test &  Evaluation  Master  Plan  (TEMP),  and  the  Simulation  Support  Plan  (SSP).    (T-2)  Unless directed  by  the  Requiring  Agency,  OSD,  joint  service,  or  other  external  agency,  the  plans, reports  and  other  documents  prescribed  in  this  section  should  be  consolidated  or incorporated, to the extent possible, into existing acquisition or program documents (e.g. SEP and TEMP), while ensuring program requirements are met. 7.6.1.  Simulation  Support  Plans  (SSPs)  are  program  documents  that  span  the  many simulations,  their  purpose,  and  their  expected  credibility.    They  typically  start  with  a program office-level simulation support group of M&S experts who advise the program on M&S opportunities, establish the VV&A process,  and document these procedures in the  SSP,  which  extends  across  the  life  cycle  of  the  system  development,  testing,  and employment.  It  is  vital  that  the  SSP  be  fully  coordinated  with  the  Test  &  Evaluation Master Plan (TEMP). 7.6.2.  During  the  V&V  process  of  the  M&S,  V&V  of  the  data  will  also  be  occurring. This execution of the M&S is an iterative process that will continue until the M&S and data  meets  their  intended  use.    The  various  V&V  techniques  are  available  in  the  DoD VV&A Recommended Practices Guide. 7.7.  Data  V&V.    Data  V&V  examines  the  data  used  to  develop  and  run  the  M&S.  Data credibility is dependent not only on how the data are produced and maintained, but on how the data are transformed and used in the M&S. Data verification is conducted to ensure that the  data  selected  are  the  most  appropriate  for  the  application  and  are  properly  prepared  or transformed  for  use  in  the  M&S.  Data  validation  is  conducted  to  ensure  that  the  data accurately represent aspects of the real world to be simulated. 7.7.1.  Data  that  require  V&V  fall  into  five  categories:  data  needed  to  (1)  verify  M&S requirements;  (2)  build  the  conceptual  model;  (3)  validate  the  M&S;  (4)  perform experiments; and (5) run M&S decision aids.  It is important that the data used to develop and  validate  M&S  are  the  right  data  to  use.  Data  V&V  activities  should  be  integrated along with the other V&V tasks to ensure that data are used for the appropriate purpose. 7.7.2.  MSEAs are designated to serve as domain SMEs for the M&S community. Their roles  are  to  provide  timely  and  authoritative  representations  of  the  natural  environment and  systems,  and  to  establish  V&V  procedures  for  common  and  general-use  M&S representations and their data. The MSEAs are sources of valid and certified M&S data. 7.7.3.  Data verification,  validation, and certification ensures that the data  used in  M&S applications is credible and constitutes the best available data for that use. 16 AFI16-1001  22 JUNE 2016 7.8.  V&V Report.  V&V agents will forward the V&V report and supporting documentation to  the  accreditation  agent  for  inclusion  into  the  accreditation  report.  (T-2)    A  copy  of  this report and documentation is forwarded to the appropriate model or simulation V&V manager for update and  archiving purposes.  A sample format for the report is  available in  the DoD VV&A RPG. 7.9.  Accreditation Assessment.   The following are the minimum  requirements  that must be assessed by the accreditation authority (or the designated accreditation agent) each time the model is accredited for a particular application: 7.9.1.  Review  the  model  and/or  simulation’s  application  domain  based  upon  a description of capabilities by the developer. (T-0) 7.9.2.  Review  the  adequacy  of  the  model's  configuration  version  control;  and  complete an acceptable face validation examination, if appropriate. (T-0) 7.9.3.  Compare the model and/or simulation’s capabilities and credibility, based on V&V status, to the acceptance criteria. (T-0) 7.9.4.  Assess  the risk of using the model and/or  simulation’s capabilities if they do not meet application criteria thresholds, or have not had sufficient V&V.  (T-0) 7.9.5.  Ensure  that  model  documentation  exists  and  is  current  and  sufficient  for  the intended  use.  This  documentation  will  normally  include  the  conceptual  model,  user's guide, programmer's and analyst's manual(s).  (T-0) 7.9.6.  Ensure  that  data  sources  have  been  identified  and  both  producer  and  user  data validation and verification activities were accomplished. (T-0) 7.10.  Accreditation Report.   The accreditation agent, based on the accreditation assessment, along  with  any  additional  V&V  activities,  and  independent  endorsements  from  bodies  with appropriate  technical/domain  expertise,  will  prepare  an  accreditation  report.  (T-2)  The accreditation  authority  will  make  and  document  the  model  accreditation  decision.    The accreditation  agent  will  forward  a  copy  of  the  accreditation  report  to  the  appropriate  M&S V&V manager for update and archiving purposes. (T-2) This report summarizes the evidence used to support the accreditation decision.  The report shall contain the information outlined in DoDI 5000.61. (T-2)  A sample format for the report is available in the DoD VV&A RPG.  Based  on  the  Accreditation  Report  and  a  recommendation  for  accreditation,  a  decision  is made  and  documented  (T-0).  The  accreditation  authority  has  several  decision  options available: 7.10.1.  Full Accreditation: M&S produces results that are sufficiently credible to support the application. 7.10.2.  Limited Accreditation: Constraints are placed on how the simulation can be used based upon the evidence assessed, the need for additional information to be provided, or modifications required to the M&S. 7.10.3.  Non-accreditation: Results of the assessment show that the simulation is not fit to support the application. 7.11.  Accrediting  Reused  M&S.  Reuse  encompasses  not  only  the  use  of  a  model  or simulation itself, or components of the model or simulation, but also leveraging the VV&A AFI16-1001  22 JUNE 2016 17 artifacts  (documentation,  test  results,  and  reports).  Accreditation  by  definition  is  for  a specific intended use. Accreditation for the intended use determines whether the M&S can be applied  for  a  unique  purpose.  Accreditation  for  reuse  then  must  focus  on  the  new  intended use of the M&S. Accrediting for a new intended use, or re-accreditation, requires that a new accreditation decision be made. If the M&S is to be reused, then the M&S must be accredited for the new intended use. 7.11.1.  Reusing previously accredited simulations will require some level of VV&A.  If the  intended  use  is  similar,  then  little  effort  may  be  required.  If  the  intended  use  is different, then significant V&V effort might be necessary. If the use is the same, but the system modeled has changed, then the M&S must be accredited to determine whether it still represents the modeled system and is the right M&S for the intended use. 7.11.2.  If the M&S has changed and the intended use is the same or similar to the one for which  it  was  originally  accredited,  then  the  changes  to  the  M&S  must  be  verified  and validated  to  determine  the  impact,  if  any,  to  the  intended  use.  The  changes  made  to  a previously  accredited  M&S  should  have  been  kept  under  configuration  control  and documented, making the V&V easier to do. 7.11.3.  The  V&V  accomplished  for  a  prior  accreditation  should  be  reexamined  and reused, if applicable, when building an accreditation package for the new intended use. 7.12.  Accreditation Status Maintenance.  The V&V Manager is responsible for maintaining the  status  of  the  model  in  the  respective  repositories,  including  any  changes  to  the accreditation status for the model. (T-2) 8.  VV&A Documentation.  This section defines the minimum set of items to document as part of  implementing  the  verification,  validation,  and/or  accreditation  processes  for  models, simulations, and associated data.  The use of standardized templates will help enable the efficient reuse  of  M&S  data  and  tools.    Note  that  unless  directed  by  the  Requiring  Agency,  OSD,  joint service, or other external agency the documentation may be incorporated into other products and may  not  have  to  be  produced  as  separate  products.    Sample  formats  for  the  various  VV&A reports are available in the RPG.  The VV&A Documentation Tool (VDT) is a web-based system that assists with capturing VV&A information in a consistent form, with consistent content, that meets requirements for sharing, discovery, and retrieval.  It is available at http://vdt.msco.mil/. 8.1.  Common documentation requirements per DoDI 5000.61: 8.1.1.  Identification of the date performed and the person or organization performing the verification, validation, and/or accreditation activities. (T-0) 8.1.2.  Identification  of  the  version  and/or  release  of  the  model,  simulation,  and associated data being verified, validated, and/or accredited. (T-0) 8.1.3.  Identification of the specific intended use of the model, simulation, and associated data being verified, validated, and/or accredited. (T-0) 8.1.4.  List  of,  or  reference  to  the  requirements  for  development,  modification,  and/or requirements for use and associated acceptability criteria for the model, simulation,  and associated data being verified, validated, and/or accredited. (T-0) 8.1.5.  List descriptions of the verification, validation, and/or accreditation activities. (T-0) 18 AFI16-1001  22 JUNE 2016 8.2.  Additional Documentation Requirements for Verification and Validation.  Summary of results, including the capabilities, limitations, risks, potential impacts to the specific intended use,  and  assumptions  of  the  model,  simulation  and  associated  data  undergoing  verification and validation. (T-3) 8.3.  Additional documentation requirements for accreditation activities. 8.3.1.  Summary of the results of the accreditation assessment. 8.3.2.  Identification  of  the  user  and/or  accreditation  authority  and  record  of  the accreditation decision. 9.  VV&A Repository.  In conjunction with the model manager, the V&V manager will use the M&S Catalog or establish, operate, or maintain a repository accessible via the M&S Catalog (T-1).  The V&V manager will ensure their repository is consistent and compatible with the M&S Catalog.  (T-1)  Repository operations must facilitate M&S community queries and data access to  establish  the  current  model  version’s  baseline  V&V  status  and  model  VV&A  and  usage history. (T-1)  Additionally, the repository will contain pointers to documentation on all ongoing and  completed  VV&A  (stand-alone  and  Federation-related)  activities,  such  items  as  test  input data  sets,  V&V  plans,  and  documented  conceptual  and  data  models,  that  will  allow  potential users  to  evaluate  the  model’s  capabilities  against  their  M&S  requirements.  (T-1)    The  M&S Catalog  is  available  to  all  model  users  and  is  the  primary  repository  for  DoD  M&S  systems. Systems  may  employ  other  registries  (e.g.,  Space  and  Cyberspace  Analysis  Resource  Portal (SARP),  web  link:  https://halfway.peterson.af.mil/SARP/)  if  they  have  classification  or  other issues that preclude the use of the M&S Catalog. To the maximum extent possible, upload M&S discovery metadata to a system capable of providing data to the OSD repository in the required format and includes all required information per DoDI 5000.70. 10.  Multi-Model  or  Federated  Architectures.  In  general,  each  component  model  or simulation being considered for inclusion in the distributed architecture would be identified and separately  validated  and  verified  for  intended  Distributed  Interactive  Simulation  (DIS)  or  High Level  Architecture  (HLA)  usage.    The  entire  distributed  architecture  is  then  assembled  and validated  and  verified  as  a  single  entity,  with  the  V&V  level  of  effort  tailored  to  support acceptability  criteria  given  accreditation  authority-identified  constraints.    When  different  M&S are used together, individual M&S components will be validated and verified independently and the  entire  architecture  will  be  validated  and  verified  as  a  combination  with  the  V&V  level  of effort tailored to support acceptability criteria given accreditation authority-identified constraints.  (T-1)  V&V reporting will be on the components and their combinations. 10.1.  Models that are individual components in a DIS or HLA architecture will be validated and  verified  for  the  specified  use  (T-2).    The  accreditation  sponsor  is  responsible  for implementing  and  funding  those  VV&A  activities  required  to  prepare  and  subsequently integrate the stand-alone model into the exercise.  For joint exercises, Air Force constructive models portraying force structure, doctrine, and tactics representations will be validated and verified  for  use  in  the  particular  exercise  in  accordance  with  paragraph  10.5,  and  approved for use by the appropriate HQ USAF DCS or ACS (or designated representative).  (T-2) All other models--whether being  submitted for  first  time DIS or  HLA use, or reuse of  a model currently residing in a DIS or HLA repository--would be validated and verified and approved for use via MAJCOM, FOA, or DRU procedures (T-2). AFI16-1001  22 JUNE 2016 19 10.2.  When  the  Air  Force  is  the  DIS  or  HLA  accreditation  sponsor,  the  sponsor  should reference  the  IEEE  document  1278.4-1997,  Recommended  Practice  for  Distributed Interactive  Simulation  -  Verification,  Validation,  and  Accreditation  for  tailoring  and constructing  the  DIS  exercise.  This  document  identifies  specific  points  for  development  of both the V&V plan and report. 10.3.  An  Air  Force  V&V  focal  point,  normally  a  member  of  the  Air  Component Commander's  staff,  will  be  designated  for  joint  HLA  exercises  that  use  models  portraying Air  Force  force  structure,  doctrine,  and  tactics  representations.    Otherwise,  the  focal  points for  a  joint  HLA  exercises  will  be  identified  by  the  participating  Air  Force  agencies  and approved by AF/A3OT. 10.4.  DIS or HLA V&V Manager (focal point): 10.4.1.  For  a  DIS  or  HLA  environment  owned  by  the  Air  Force,  the  Air  Force accreditation sponsor is responsible for overall management responsibilities (component model, VV&A, and configuration management). 10.4.2.  For  a  joint  DIS  or  HLA  environment,  and  Air  Force  is  not  designated  as  the accreditation  sponsor,  the  Air  Force  exercise  POC  (or  designated  representative)  will represent the Air Force on issues concerning the DIS or HLA environment and Air Force models within the DIS or HLA confederation.  This Air Force focal point will coordinate the VV&A requirements with the joint DIS or HLA manager.  (T-1) 10.5.  The accreditation of a federation of M&S will include a determination that: 10.5.1.  Federation elements can appropriately exchange data. (T-2) 10.5.2.  Data items being exchanged are accurate and correct to the extent required across the federation. (T-2) 10.5.3.  System response times meet the LVC scenario’s requirements. (T-2) 10.5.4.  The  federation  meets  the  functionality,  appearance,  performance,  fidelity,  and interoperability requirements for the intended purpose.  (T-2) 10.5.5.  Security  classification  levels  of  the  federation  and  data  are  appropriate  and commensurate with the application. (T-2)  JOHN W. RAYMOND, Lt Gen, USAF Deputy Chief of Staff, Operations 20 AFI16-1001  22 JUNE 2016 GLOSSARY OF REFERENCES AND SUPPORTING INFORMATION Attachment 1 References DoD Directive 5000.59, DoD Modeling and Simulation (M&S) Management, 8 August 2007 DoD Instruction 5000.61, DoD Modeling and Simulation (M&S) Verification, Validation, and Accreditation, (VV&A), 9 December 2009 DoD Instruction 5000.70, Management of DoD Modeling and Simulation (M&S) Activities, 10 May 2012, Change 1, 19 March 2014 DoD 7000.14-R, Department of Defense Financial Management Regulation, June 2011 AFI 33-360, Publications and Forms Management, 1 December 2015 AFPD 16-10, Modeling and Simulation, 23 January 2015 AFI 63-101/20-101, Integrated Life Cycle Management, 7 March 2013 AFI 99-103, Capabilities-Based Test and Evaluation, 16 October 2013 AFMAN 33-363, Management of Records, 1 March 2008, Incorporating Change 1, 28 January 2015 MIL-STD-3022, Documentation of Verification, Validation, and Accreditation (VV&A) For Models and Simulations, 5 April 2012 (w/ CHANGE 1) IEEE document 1278.4-1997, Recommended Practice for Distributed Interactive Simulation - Verification, Validation, and Accreditation Modeling and Simulation Coordination Office, VV&A Recommended Practices Guide, http://www.msco.mil/vva_rpg.html DoD M&S Glossary (http://www.msco.mil/MSGlossary.html) Adopted Forms AF Form 847, Recommendation for Change of Publication Abbreviations and Acronyms ACS—Assistant Chief of Staff AF—Air Force AFI—Air Force Instruction AFMAN—Air Force Manual AFPD—Air Force Policy Directive ASNE—Air and Space Natural Environment DCS—Deputy Chief of Staff DIE—Defense Intelligence Enterprise DIS—Distributed Interactive Simulation AFI16-1001  22 JUNE 2016 21 DoD—Department of Defense DRU—Direct Reporting Unit FFRDC—Federally Funded Research and Development Center FOA—Field Operating Agency HLA—High Level Architecture IEEE—Institute of Electrical and Electronics Engineers LVC—Live, Virtual and Constructive MAJCOM—Major Command M&S—Modeling and Simulation MSEA—Modeling and Simulation Executive Agent RDT&E—Research, Development, Test and Engineering RPG—Recommended Practices Guide TRWG—Technical Review Working Group VV&A—Verification, Validation and Accreditation VV&C—Verification, Validation, and Certification Terms Accreditation—The official certification that a model or simulation and its associated data are acceptable for use for a specific purpose. (DoDI 5000.61) Authoritative Data Source—A recognized or official data production source with a designated mission statement or source/product to publish reliable and accurate data for subsequent use by customers. An authoritative data source may be the functional combination of multiple, separate data sources. Data  certification—The  determination  that  data  have  been  verified  and  validated.  Data  user certification  is  the  determination  by  the  designated  agent  that  data  have  been  verified  and validated  as  appropriate  for  the  specific  M&S  usage.  Data  producer  certification  is  the determination  by  the  data  producer  that  data  have  been  verified  and  validated  against documented standards or criteria. Data  producer—Refers  to  a  program,  an  organization(government  and/or  commercial),  a person,  or  even  a  machine  process  that  controls,  manufactures,  and/or  maintains  data  assets within  the  Department,  other  government  activities  in  the  National  Security  Arena,  as  well  as allied/coalition  partners.  Data  providers  include  operators  and  supporting  developers  who  use resources provided by DoD programs of record (PoRs) to create and/or expose data to significant audiences. Data  validation—The  documented  assessment  of  data  by  subject  area  experts  and  its comparison to known values. Data user validation is an assessment, as appropriate, for use in an intended M&S. Data producer validation is an assessment within stated criteria and assumptions. 22 AFI16-1001  22 JUNE 2016 Data verification—Data producer verification is the use of techniques and procedures to ensure that data meets constraints defined by data standards and business rules derived from process and data modeling. Data user verification is the use of techniques and procedures to ensure that data meets  user  specified  constraints  defined  by  data  standards  and  business  rules  derived  from process and data modeling, and that data are transformed and formatted properly. Data  Verification,  Validation,  and  Certification  (VV&C)—The  process  of  verifying  the internal  consistency  and  correctness  of  data,  validating  that  it  represents  real-world  entities appropriate for its intended purpose or an expected range of purposes, and certifying it as having a specified level  of quality or  as being appropriate for a specified use, type of use, or  range of uses. The process has two perspectives: producer and user process. Distributed  Interactive  Simulation  (DIS)—(1)  Program  to  electronically  link  organizations operating  in  the  four  domains:  advanced  concepts  and  requirements;  military  operations; research, development, and acquisition; and training. (2) A synthetic environment within which humans  may  interact  through  simulation(s)  at  multiple  sites  networked  using  compliant architecture, modeling, protocols, standards, and data bases. Face  validation—The process of determining whether a model or simulation seems reasonable to  people  who  are  knowledgeable  about  the  system  under  study,  based  on  performance.  This process does not review the software code or logic, but rather reviews the inputs and outputs to ensure that they appear realistic or representative. Federation  of  models  and  simulations—A  system  of  interacting  models,  simulations,  and supporting infrastructure that are based on a common understanding of the objects portrayed in the system. (MIL-STD-3022) High  level  Architecture  (HLA)—Major  functional  elements,  interfaces,  and  design  rules, pertaining, as feasible, to all DOD simulation applications and providing a common framework within which specific system architectures can be defined. Key  M&S  asset—An  M&S  tool,  data  set,  or  service,  including  models,  simulations,  or  data assets, that either exceeds $5M in annual expenditures, or is less than $5M but determined by the DoD  Component  to  be  “key.”  The  total  annual  expenditure  will  be  determined  using  standard justification documentation for DoD appropriations, such as RDT&E (R-docs), Procurement (P-docs), and O&M (O&M exhibits), which are provided to Congress pursuant to DoD 7000.14-R, Department of Defense Financial Management Regulation. Model  Manager—Refers  to  an  organization  (government  and/or  commercial)  or  a  person  that will  endeavor  to  satisfy  the  Requiring  Agency’s  need.    The  model  manager  will  undertake activities  such  as  project  management  and  overseeing  development  of  the  model.  This  will typically  include  subject-matter  experts  providing  mission  space  knowledge  and  knowledge engineers eliciting, structuring and documenting knowledge. Modeling  and  Simulation  (M&S)—The  use  of  models,  including  emulators,  prototypes, simulators, and stimulators, either statically or over time, to develop data as a basis for making managerial  or  technical  decisions.  The  terms  "modeling"  and  "simulation"  are  often  used interchangeably. M&S assets—M&S tools, data, and services, including models and simulations, and data assets. AFI16-1001  22 JUNE 2016 23 M&S  data—Data  used  to  develop  models  or  simulations,  data  used  as  input  to  models  and simulations, and data produced by models and simulations. M&S  Executive  Agents  (MSEA)—MSEAs are designated by the Under Secretary of Defense for Acquisition, Technology, and Logistics to serve as domain SMEs for the M&S community. Their roles are to provide timely and authoritative representations of the natural environment and systems,  and  to  establish  V&V  procedures  for  common  and  general-use  M&S  representations and their data.  The MSEAs are sources of valid M&S data. Metadata—Searchable  information  describing  the  characteristics  of  data;  data  or  information about  data;  or  descriptive  information  about  an  object’s  data,  data  activities,  systems,  and holdings.  For  example,  metadata  for  a  model  or  simulation  will  include  keywords  and  a description of the capabilities along with developer and user information. Model—A  physical,  mathematical,  or  otherwise  logical  representation  of  a  system,  entity, phenomenon, or process. Reuse—The practice of using again, in whole or part, existing M&S tools, data, or services. Simulation—A method for implementing a model over time. Simulations are typically described as live, virtual, constructive, or a combination, depending on the application. Validation—The  process  of  determining  the  degree  to  which  a  model  or  simulation  and  its associated  data  are  an  accurate  representation  of  the  real-world  from  the  perspective  of  the intended uses of the model.  (DoDI 5000.61) Verification—The  process  of  determining  that  a  model  or  simulation  implementation  and  its associated  data  accurately  represents  the  developer's  conceptual  description  and  specifications. (DoDI 5000.61)  