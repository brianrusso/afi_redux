{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pdf2txt.py -o afi34-201.html -t html afi/afi34-201.pdf\n",
    "\n",
    "import topycal\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "INSTR_PATH = os.path.join(os.getcwd(),\"afi_txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, wait, as_completed\n",
    "def do_fn_on_iter(fn, iterator, num_threads=6):\n",
    "    futures = []\n",
    "    if isinstance(num_threads, str):\n",
    "        num_threads = int(num_threads)\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        for elem in iterator:\n",
    "            futures.append(executor.submit(fn, elem))\n",
    "    results = []\n",
    "    for x in as_completed(futures):\n",
    "        results.append(x.result())\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_file_list(limit=500, shuffle=True):\n",
    "    files = glob.glob(\"{}/afi*.txt\".format(INSTR_PATH))\n",
    "    if shuffle:\n",
    "        random.shuffle(files)\n",
    "    if limit:\n",
    "        return files[0:limit]\n",
    "    else:\n",
    "        return files\n",
    "    #data = myfile.read()\n",
    "    \n",
    "def read_file(fname):\n",
    "    with open(fname, errors='replace') as fd:\n",
    "        return fd.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_list = get_file_list(limit=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "def read_file(fname):\n",
    "    with open(fname, 'r') as myfile:\n",
    "        return re.sub(\"\\s+\",' ',myfile.read())\n",
    "\n",
    "def write_file(fpath, string):\n",
    "    with open(fpath, 'w') as myfile:\n",
    "        return myfile.write(string)\n",
    "    \n",
    "def load_file(fname):       \n",
    "    with open(fname, 'r') as myfile:\n",
    "        #contents = re.sub(r'[\\t\\n\\r\\x0b\\x0c]',' ', myfile.read())\n",
    "        contents = myfile.read()\n",
    "        return (os.path.basename(fname),re.sub(\"\\s+\",' ', contents))\n",
    "\n",
    "def load_corpus(file_list):\n",
    "    return {f[0]:f[1] for f in do_fn_on_iter(load_file, file_list)}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus_dict = load_corpus(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#corpus_dict['afi10-244.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'warrior'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = \"the warrior\"\n",
    "foo[0:4] in ['the ','The ']\n",
    "foo[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textstat.textstat import textstat\n",
    "\n",
    "def get_num_words(sent):\n",
    "    return len([word for word in sent if word.text.isalpha()])\n",
    "\n",
    "def get_num_syllables(sent):\n",
    "    return textstat.syllable_count(sent.text)\n",
    "\n",
    "def get_np_regexcands(string):\n",
    "    propnounregexp = r\"(?:[A-Z][a-z]{2,}\\s*(?:and|of)?\\s*){3,}\"\n",
    "    p = re.compile(propnounregexp)\n",
    "    nps = list(set(p.findall(string)))\n",
    "    return nps\n",
    "\n",
    "def get_np_cands(string):\n",
    "    nps = []\n",
    "    doc = nlp(string)\n",
    "    for np in doc.noun_chunks:\n",
    "        nps.append(np)\n",
    "    return nps\n",
    "\n",
    "def get_nounphrases(string,blacklist=['AFI','AFPD']):\n",
    "    new_cands = []\n",
    "    cands = get_np_cands(string)\n",
    "    for cand in cands:\n",
    "        # If starts with the.. strip it off\n",
    "        if cand.text[0:4] in ['The ','the ']:\n",
    "            cand = cand[4:]\n",
    "        elif cand.text[0:2] in ['a ','A ']:\n",
    "            cand = cand[2:]\n",
    "        #new_cands.append(cand.text.strip())\n",
    "        num_words = get_num_words(cand)\n",
    "        if 3 <= num_words <=9:\n",
    "            #print(num_words)\n",
    "            #print(cand.text)\n",
    "            if not any(blackword in cand.text for blackword in blacklist):\n",
    "                if get_num_syllables(cand)/num_words > 4:\n",
    "                    new_cands.append(cand.text.strip())\n",
    "                \n",
    "                elif len(cand.text)/num_words > 7:\n",
    "                    new_cands.append(cand.text.strip())\n",
    "    spacy_cands = list(set(new_cands))\n",
    "    regex_cands = get_np_regexcands(string)\n",
    "    #print(regex_cands)\n",
    "    return list(set(spacy_cands + regex_cands))\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def find_reference_candidates(string):\n",
    "    cands = []\n",
    "    refregexps = [r\"AF[A-Z]+\\s?\\d+[A-Z0-9-]+\\d+\\-?\\d*\",r\"CJ\\w+\\s\\d+\\.\\d+[A-Z]?\",r\"JP\\s\\d\\-?\\d\",\n",
    "                  r\"(?:DODFMR|DoD|DTR|DODI|DoDI|DoDD|DoD\\sDirective)\\s\\d+\\.?\\d*\",\n",
    "                 \"(?:SF|DD|AF|AFTO)+\\s+Form\\s\\d+\"]\n",
    "    for regexp in refregexps:\n",
    "                  p = re.compile(regexp)\n",
    "                  cands += p.findall(string)\n",
    "    \n",
    "    return cands\n",
    "\n",
    "def find_references(string):\n",
    "    cands = list(set(find_reference_candidates(string)))\n",
    "    stoprefs = ['AF']\n",
    "    for ref in stoprefs:\n",
    "        try:\n",
    "            cands.remove(ref)\n",
    "        except ValueError:\n",
    "            pass      \n",
    "    cands.sort()\n",
    "    return cands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "# find acronyms\n",
    "def find_acronym_candidates(string):\n",
    "    acroregexp = r\"\\([A-Z]{3}[A-Za-z]*\\)\"\n",
    "    p = re.compile(acroregexp)\n",
    "    uniqued = list(set(p.findall(string)))\n",
    "    return [cand[1:-1] for cand in uniqued]\n",
    "\n",
    "stopronyms = ['AFPD','AFI','REQUIRED','Conventional','Hijacking','Name']\n",
    "knownronyms = ['FOA','DRU','DSN','IAW','ULN','FAM','MAJCOM','ALN']\n",
    "def find_acronyms(string):\n",
    "    cands = find_acronym_candidates(string)\n",
    "    for s in stopronyms:\n",
    "        try:\n",
    "            cands.remove(s)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    for known in knownronyms:\n",
    "        cands.append(known)\n",
    "    #cands.sort()\n",
    "    cands.sort(key = len, reverse=True)\n",
    "    return cands\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def monkeypatch_css(htmlstr):\n",
    "    css = \"\"\"\n",
    "    \n",
    "    \n",
    "    <style>\n",
    "    \n",
    "/**\n",
    " * Tooltip Styles\n",
    " */\n",
    "\n",
    "/* Add this attribute to the element that needs a tooltip */\n",
    "[data-tooltip] {\n",
    "  position: relative;\n",
    "  z-index: 2;\n",
    "  cursor: pointer;\n",
    "}\n",
    "\n",
    "/* Hide the tooltip content by default */\n",
    "[data-tooltip]:before,\n",
    "[data-tooltip]:after {\n",
    "  visibility: hidden;\n",
    "  -ms-filter: \"progid:DXImageTransform.Microsoft.Alpha(Opacity=0)\";\n",
    "  filter: progid: DXImageTransform.Microsoft.Alpha(Opacity=0);\n",
    "  opacity: 0;\n",
    "  pointer-events: none;\n",
    "}\n",
    "\n",
    "/* Position tooltip above the element */\n",
    "[data-tooltip]:before {\n",
    "  position: absolute;\n",
    "  bottom: 150%;\n",
    "  left: 50%;\n",
    "  margin-bottom: 5px;\n",
    "  margin-left: -80px;\n",
    "  padding: 7px;\n",
    "  width: 160px;\n",
    "  -webkit-border-radius: 3px;\n",
    "  -moz-border-radius: 3px;\n",
    "  border-radius: 3px;\n",
    "  background-color: #000;\n",
    "  background-color: hsla(0, 0%, 20%, 0.9);\n",
    "  color: #fff;\n",
    "  content: attr(data-tooltip);\n",
    "  text-align: center;\n",
    "  font-size: 14px;\n",
    "  line-height: 1.2;\n",
    "}\n",
    "\n",
    "/* Triangle hack to make tooltip look like a speech bubble */\n",
    "[data-tooltip]:after {\n",
    "  position: absolute;\n",
    "  bottom: 150%;\n",
    "  left: 50%;\n",
    "  margin-left: -5px;\n",
    "  width: 0;\n",
    "  border-top: 5px solid #000;\n",
    "  border-top: 5px solid hsla(0, 0%, 20%, 0.9);\n",
    "  border-right: 5px solid transparent;\n",
    "  border-left: 5px solid transparent;\n",
    "  content: \" \";\n",
    "  font-size: 0;\n",
    "  line-height: 0;\n",
    "}\n",
    "\n",
    "/* Show tooltip content on hover */\n",
    "[data-tooltip]:hover:before,\n",
    "[data-tooltip]:hover:after {\n",
    "  visibility: visible;\n",
    "  -ms-filter: \"progid:DXImageTransform.Microsoft.Alpha(Opacity=100)\";\n",
    "  filter: progid: DXImageTransform.Microsoft.Alpha(Opacity=100);\n",
    "  opacity: 1;\n",
    "}\n",
    "span.red {\n",
    "  background-color: red;\n",
    "}\n",
    "mark.nounphrase {\n",
    "  background-color: #ffa370;\n",
    "}\n",
    "mark.reference {\n",
    "  background-color: #90d2ff;\n",
    "}\n",
    "mark.acronym {\n",
    "  background-color: #3aff3a; \n",
    "}\n",
    "</style>\"\"\"\n",
    "    return htmlstr.replace(\"<html><head>\",\"<html><head>{}\".format(css))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#afi_html.find('Work timetables need to be adjusted to minimize ')\n",
    "#afi_html[1168331:1169331]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('ec130results.pickle','rb') as myfile:\n",
    "    ec130results = pickle.load(myfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTMLFILE = \"afi11-2ec-130hv3.html\"\n",
    "afi_html = read_file(os.path.join(os.getcwd(),HTMLFILE))\n",
    "afi_html = afi_html.replace('- <br>','-')\n",
    "afi_html = afi_html.replace(' <br>',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert list(ec130results.keys())[7] in afi_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert 'Work timetables need to be adjusted to minimize thermal stress caused by wearing the ACDE. Aircrews must weigh all factors when performing in-flight and ground duties.' in afi_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TXTFILE = 'afi11-2ec-130hv3.txt'\n",
    "acronyms = find_acronyms(corpus_dict[TXTFILE])\n",
    "\n",
    "nounphrases = get_nounphrases(corpus_dict[TXTFILE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "references = find_references(corpus_dict[TXTFILE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k,v in ec130results.items():\n",
    "    desc = \"Duplicated {} times across {}\".format(v[1],\", \".join([k[:-4] for k in v[0]]))\n",
    "    new_elem = '<mark class=\"dupe\" data-tooltip=\"{}\">{}</mark>'.format(desc,k)\n",
    "    afi_html = afi_html.replace(k,new_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ac in acronyms:\n",
    "    new_elem = '<mark class=\"acronym\">{}</mark>'.format(ac)\n",
    "    afi_html = afi_html.replace(ac,new_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for np in nounphrases:\n",
    "    new_elem = '<mark class=\"nounphrase\">{}</mark>'.format(np)\n",
    "    afi_html = afi_html.replace(np,new_elem)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ref in references:\n",
    "    #new_elem = '<mark class=\"reference\">{}</mark>'.format(ref)\n",
    "    new_elem = '<mark class=\"reference\" data-tooltip=\"Blah blah..\">{}</mark>'.format(ref)\n",
    "    afi_html = afi_html.replace(ref,new_elem)\n",
    "    \n",
    "afi_html = monkeypatch_css(afi_html)\n",
    "#afi_html = monkeypatch_js(afi_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2038184"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_file('afi11-2ec-130hv3-meta.html',afi_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nounphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# long sentences\n",
    "# some kind of reference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
